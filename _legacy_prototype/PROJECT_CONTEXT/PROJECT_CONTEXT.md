# Tenant Note (테넌트 노트) - 프로젝트 마스터 정의서
Last Updated: 2026-01-13 (v2.0)
Status: MVP Development & Logic Refinement

## 1. 프로젝트 개요 (Identity)
- **서비스명:** Tenant Note (테넌트 노트)
- **정의:** "빈 공책이 아니다. 데이터가 미리 써둔 **부동산 비급(족보)**이다."
- **핵심 가치:**
  1. **Visualization:** 보이지 않는 위험(경사, 소음, 치안)을 지도 위에 시각화.
  2. **Scoring:** 복잡한 등기부/건축물대장 정보를 A~D 등급으로 단순화.
  3. **Personalization:** MBTI 기반으로 1인 가구/신혼부부에게 딱 맞는 동네 추천.
- **타겟 유저:** "호갱 되기 싫지만 공부할 시간은 없는" 2030 세입자.

---

## 2. 안심 등급 산출 알고리즘 (Core Logic)

### A. 데이터 정규화 (Normalization)
1. **Min-Max Scaling:** 모든 원천 데이터를 0~1 사이 값으로 변환 후 100점 만점화.
2. **역산 처리 (Inverse):** 수치가 높을수록 나쁜 **부정 지표(범죄, 소음, 노후도, 경사도)**는 `(1 - 값)`으로 변환하여 점수화.
3. **결측 보정 (Interpolation):** 데이터 부재 시 '인접 행정동 평균값' 또는 'SGIS 격자 데이터'로 보간하여 0점 처리 방지.

### B. 가중치 적용 (Weighting)
- **기본 가중치 (Default):**
  1. **치안/안전 (30%):** CCTV, 범죄주의구간 (가장 중요)
  2. **물건/건물 (25%):** 노후도, 위반건축물, 주차장
  3. **주거 쾌적성 (15%):** 1인 가구 밀집도, 노후 주택 비율, 경사도
  4. **교통 (10%):** 지하철/버스 접근성
  5. **생활 인프라 (10%):** 편의점, 세탁소, 병원
  6. **환경 (10%):** 소음, 악취, 유해시설
- **개인화 옵션:** MBTI 유형 선택 시 해당 유형 가중치로 동적 변경.

### C. 페널티 시스템 (Kill Switch - 과락)
데이터 총점이 높아도, **치명적인 결함**이 있으면 즉시 등급을 강등함.
1. **🚨 치안 과락:** 종합 치안 점수 하위 20%(40점 미만) 지역 → **즉시 D등급**.
2. **⛰️ 경사 주의:** 경사도 10도 이상 구역 비율 30% 초과 시 → **쾌적성 점수 -30점**.
3. **🔊 소음 주의:** 야간 평균 소음 55dB 이상 또는 공항/철도 인접 시 → **환경 점수 -20점**.

### D. 등급 기준 (Grade System)
- **A (상위 15%):** 85점 이상 (초록색)
- **B (안심):** 55점 ~ 85점 미만 (파란색)
- **C (보통):** 20점 ~ 55점 미만 (주황색)
- **D (주의):** 20점 미만 또는 과락 발생 시 (빨간색)

---

## 3. 데이터 구조 (Data Schema)

### A. 매물 객체 (`item`) 표준
```json
{
  "id": "String",
  "type": "Code (APT | OP | YH | DD)", 
  "name": "String",
  "price": { "d": Number, "r": Number },
  "slope": Number (0~25도),
  "noiseLevel": Number (dB),
  "features": ["String"], // 예: ["소음 주의", "슬세권"]
  "scores": { "security": 45, "comfort": 80, ... } // 정규화된 점수
}

### B. 주거 유형 코드 & 컬러
APT (아파트): #3B82F6 (Blue)
OP (오피스텔): #8B5CF6 (Purple)
YH (연립/다세대): #F97316 (Orange)
DD (단독/다가구): #22C55E (Green)

## 4. 데이터 소스 (Data Sources) - *Complete v2.0*

| 구분 | 데이터명 | 출처 | 핵심 용도 및 산출 근거 |
| :--- | :--- | :--- | :--- |
| **통계/인구** | **SGIS 소지역 통계 (집계구)** | **통계청** | **1인 가구 밀집도, 노후 주택 비율 (주거 쾌적성 핵심 산출 근거)** |
| **구역/경계** | **행정구역 경계 데이터 (SHP)** | **국토교통부** | **지도상 행정동 폴리곤 시각화 및 등급별 색상 채우기 (필수)** |
| **도로/보행** | **전국 일방통행도로 표준데이터** | **행정안전부** | **안심 귀가 경로 산출, 보행자 안전 지수(차량 속도 제한 구역) 분석** |
| **부동산** | 국토교통부 실거래가 정보 | 공공데이터포털 | 매매/전월세 가격, 거래량 분석 |
| **건물정보** | 건축물대장 (표제부/전유부) | 공공데이터포털 | 층수, 주차대수, **난방방식(개별/중앙)**, **위반건축물 여부** |
| **지형/경사** | 수치표고모델 (DEM) | 국토지리정보원 | **경사도(Slope)** 분석 (평지/언덕 구분) |
| **치안/안전** | 생활안전지도, CCTV 표준데이터 | 경찰청/공공데이터 | 범죄주의구간 회피, CCTV 밀집도 가점 |
| **상권/인프라** | 지방행정 인허가 데이터 | 로컬데이터 | **학원(입시/어학 분류)**, 세탁소, 병원 등 편의시설 밀집도 |
| **환경/소음** | 국가소음정보시스템 측정망 | 한국환경공단 | 공항/철도/대로변 **소음도(dB)** 및 악취 페널티 적용 |
| **주소/좌표** | 도로명주소 전자지도 | 행정안전부 | 지번/도로명 주소와 위경도 매칭 (Geocoding) |

5. GIS 기술 전략 (Coordinate System Strategy)
A. 이중 좌표계 운영 (Dual Coordinate System)
성능(분석)과 호환성(표출)을 위해 저장과 서비스 단계를 분리함.
분석 및 저장 (Backend/DB): EPSG:5179 (GRS80 UTM-K)
이유: 미터(m) 단위 좌표계로 반경 검색, 밀도 계산, 면적 산출 등 공간 연산에 최적화.
적용: PostGIS Geometry 컬럼 저장 표준.
서비스 표출 (Frontend): EPSG:4326 (WGS84)
이유: 카카오맵, 네이버맵 등 웹 지도 API와의 호환성 필수.
적용: 클라이언트로 데이터 전송 시 변환 (ST_Transform).

B. 데이터 파이프라인 (ETL) & 좌표 변환
[주의] 원본 데이터 좌표계를 정확히 확인하여 5179로 통일할 것. 5186(행정구역)과 혼동 주의.
Source 좌표계 확인:
EPSG:5179: 건축물대장, 도로명주소 (변환 불필요)
EPSG:5186: 행정구역 경계(SHP), 공시지가 (변환 필수)
EPSG:5174: 구 토지대장 (보정 파라미터 적용 필수)
EPSG:4326: 버스정류장, 위경도 좌표
Python 변환 코드 (예시: 5186 → 5179):
from pyproj import Transformer
import geopandas as gpd

# 1. 변환기 정의 (행정구역 경계 5186 -> 분석 표준 5179)
transformer = Transformer.from_crs("EPSG:5186", "EPSG:5179", always_xy=True)

# 2. GeoPandas 일괄 변환
gdf = gpd.read_file("admin_boundary.shp", encoding='euc-kr') # 보통 5186
if gdf.crs != "EPSG:5179":
    gdf = gdf.to_crs("EPSG:5179")

# 3. DB 적재 (PostGIS)
# SQL: CREATE INDEX idx_geom ON table_name USING GIST(geom);

---

## 8. 미래 기능 설계 (AI Automation Roadmap) - 이거는 임시로만 돌아가는 중.

지금 당장 복잡한 서버를 구축할 필요는 없습니다. 하지만 **'나중에 AI를 꽂을 수 있는 구멍'**을 미리 파두는 작업은 필요합니다.

1. 리뷰 데이터 수집 창구 만들기 (프론트엔드)

상세 페이지 하단에 "이 동네 살아본 썰 풀기" 같은 간단한 입력창을 만들어두세요.

데이터가 없으면 AI도 분석을 못 합니다. 초기에는 "관리비", "소음", "치안" 3가지 키워드라도 선택하게 해야 합니다.

2. Python 환경과 친해지기 (백엔드 준비)

이 모든 자동화는 자바스크립트(브라우저)가 아니라 **Python(파이썬)**에서 이루어집니다.

나중에 LangChain 같은 도구를 써서 **"공공데이터 API + 리뷰 DB + GPT API"**를 연결하는 코드를 짜게 될 것입니다.

3. PROJECT_CONTEXT.md에 미래 설계 박제하기

나중에 개발자가 오거나, 제가 코드를 짜드릴 때 잊어버리지 않도록 아래 내용을 추가해두세요.

### A. AI 기반 SWOT 자동 생성 파이프라인
현재의 규칙 기반(Rule-based) 로직을 향후 **LLM(Large Language Model) 기반 자동화**로 전환한다.

1.  **Input (입력):**
    * **공공데이터(Hard Data):** 점수화된 6대 지표, 경사도, 소음 수치.
    * **사용자 리뷰(Soft Data):** 실거주자가 남긴 텍스트 리뷰, 별점, 키워드.
    * **외부 뉴스(Trend):** 해당 행정동 관련 부동산 뉴스(호재/악재).

2.  **Process (처리):**
    * **Trigger:** 매물 등록 시점 또는 리뷰 10건 누적 시점.
    * **Engine:** OpenAI API (GPT-4o) or Google Gemini API.
    * **Action:** 정량 데이터와 정성 리뷰를 결합하여 모순점을 분석하고 통찰력 있는 문장 생성.
        * *예: "수치상 치안은 좋지만(CCTV 많음), 리뷰상 골목이 어두워 체감 안전은 낮음" 도출.*

3.  **Output (출력):**
    * 생성된 SWOT JSON을 DB의 `listings` 테이블 `swot` 컬럼에 캐싱(Caching)하여 제공.

    ---

## 9. 고급 분석 알고리즘 (Advanced Analysis Logic)
*단순 현황(Static)이 아닌, 시계열 변화(Delta)를 분석하여 미래 가치를 예측함.*

### A. 📈 개발 호재 포착 (Opportunities)
**"뜨는 동네를 데이터로 선점한다."**

1.  **재건축/재개발 시그널 (Redevelopment Signal)**
    * **Data:** 건축물대장 표제부, SGIS 노후 주택 비율.
    * **Logic:** 행정동 내 **30년 이상 노후 건축물 비율** 60% 이상 && **접도율(도로 접합)** 불량 지역 필터링.
    * **Insight:** "안전진단 통과 임박", "재개발 노후도 충족" 멘트 생성.

2.  **젠트리피케이션/상권 부흥 (Gentrification)**
    * **Data:** 지방행정인허가 (휴게음식점-카페, 일반음식점-양식/일식).
    * **Logic:** 최근 1년(YoY) 신규 개업 인허가 증가율 상위 10% 행정동 추출.
    * **Insight:** "카페거리가 형성되는 힙한 동네", "젊은 층 유입 증가 예상".

3.  **학군지 확장 (Education Hub)**
    * **Data:** 지방행정인허가 (학원/교습소).
    * **Logic:** 입시/보습 학원 수가 전분기 대비 꾸준히 증가(Slope > 0)하는 지역.
    * **Insight:** "제2의 목동/대치동", "신혼부부 유입으로 전세가 방어 유력".

### B. 📉 숨겨진 리스크 탐지 (Threats)
**"임장 가야만 알 수 있는 악재를 미리 경고한다."**

1.  **소음/진동 스트레스 (Noise Risk)**
    * **Data:** 국가소음정보시스템(측정망), 공항소음대책지역 고시.
    * **Logic:** 야간 평균 소음 **55dB 초과** 지역 또는 공항/철도 반경 1km 이내.
    * **Insight:** "창문 열면 비행기 소음", "철로변 진동 주의".

2.  **주거 정온성 저해 (NIMBY Facilities)**
    * **Data:** 전국 등록공장 현황, 유흥주점 인허가.
    * **Logic:** 주거지 반경 500m 내 **유흥/단란주점** 밀집도 High 또는 **공장** 등록 건수 존재.
    * **Insight:** "새벽 취객 소음 주의", "매연/먼지 우려 지역".

3.  **치안 사각지대 (Safety Blind Spot)**
    * **Data:** 생활안전지도(범죄발생), CCTV 표준데이터.
    * **Logic:** 범죄 밀도 상위 20% AND CCTV 밀도 하위 20% (교집합 구역).
    * **Insight:** "밤길 귀가 위험 구역", "보안이 철저한 오피스텔 추천".

    💡 바로 적용 가능한 'Mock 데이터 전략'
지금 당장 이 방대한 데이터를 다 분석할 순 없으니, 프론트엔드(reviews.html)에서는 이 로직을 흉내 내서 그럴싸한 시나리오를 보여주면 됩니다.

젠트리피케이션 시뮬레이션:

Mock 데이터 생성 시, score.infra가 높은 지역 중 일부에 "☕ 최근 1년 카페 20곳 오픈" 이라는 뱃지를 붙여줍니다.

소음 리스크 시뮬레이션:

score.environment가 낮은 지역 매물에는 "✈️ 공항 소음 주의 (58dB)" 라는 멘트를 SWOT의 약점(W)에 넣어줍니다.

이렇게 **"데이터가 살아서 움직이는 느낌"**을 주는 것이 투자자(또는 사용자)를 설득하는 최고의 무기입니다. 아주 훌륭한 기획입니다!